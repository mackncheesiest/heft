# HEFT: Heterogeneous Earliest Finish Time

A Python 3.6+ implementation of a heuristic DAG scheduling approach from 

`H. Topcuoglu, S. Hariri and Min-You Wu, "Performance-effective and low-complexity task scheduling for heterogeneous computing," in IEEE Transactions on Parallel and Distributed Systems, vol. 13, no. 3, pp. 260-274, March 2002.`

[IEEE Explore Link](https://ieeexplore.ieee.org/document/993206)


### Installation
If you have conda installed, you can create an environment and fetch any necessary dependencies with

`conda env create -f heft.yml`

Otherwise, the main dependencies are:
- Python 3.6+ (uses literal string interpolation)
- Matplotlib
- Numpy
- Networkx

### Usage
Basic usage is given by `python heft/heft.py -h`

```
usage: heft.py [-h] [-d DAG_FILE] [-p PE_CONNECTIVITY_FILE]                             
               [-t TASK_EXECUTION_FILE]                                                 
               [-l {DEBUG,INFO,WARNING,ERROR,CRITICAL}] [--showDAG]                     
               [--showGantt]                                                            
                                                                                        
A tool for finding HEFT schedules for given DAG task graphs                             
                                                                                        
optional arguments:                                                                     
  -h, --help            show this help message and exit                                 
  -d DAG_FILE, --dag_file DAG_FILE                                                      
                        File containing input DAG to be scheduled. Uses                 
                        default 10 node dag from Topcuoglu 2002 if none given.          
  -p PE_CONNECTIVITY_FILE, --pe_connectivity_file PE_CONNECTIVITY_FILE                  
                        File containing connectivity/bandwidth information              
                        about PEs. Uses a default 3x3 matrix from Topcuoglu             
                        2002 if none given.                                             
  -t TASK_EXECUTION_FILE, --task_execution_file TASK_EXECUTION_FILE                     
                        File containing execution times of each task on each            
                        particular PE. Uses a default 10x3 matrix from                  
                        Topcuoglu 2002 if none given.                                   
  -l {DEBUG,INFO,WARNING,ERROR,CRITICAL}, --loglevel {DEBUG,INFO,WARNING,ERROR,CRITICAL}
                        The log level to be used in this module. Default: INFO          
  --showDAG             Switch used to enable display of the incoming task DAG          
  --showGantt           Switch used to enable display of the final scheduled            
                        Gantt chart                                                     
```

If you don't have any particular DAG that needs scheduling, the canonical example schedule from Topcuoglu et al. can be generated by passing in no args

`python -m heft.heft`

With a generated Gantt chart available using

`python -m heft.heft --showGantt`

### Usage from an external library


```
from heft import heft

pe_connectivity_file = 'test/canonicalgraph_resource_BW.csv'
task_execution_file = 'test/canonicalgraph_task_exe_time.csv'
dag_file = 'test/canonicalgraph_task_connectivity.csv'

# Initialize the relevant HEFT matrices and DAGs
communication_matrix = heft.readCsvToNumpyMatrix(pe_connectivity_file)
computation_matrix = heft.readCsvToNumpyMatrix(task_execution_file)
dag = heft.readDagMatrix(dag_file)

existing_schedules - {}
time_offset = 0

"""
Everything other than dag has a default value
proc_schedules gives a dictionary with keys being processor number and values being lists of tasks on each processor
task_schedules gives a dictioonary with keys being node number (the label in the dag) and the values being the task of a particular job, potentially relabeled
"""
proc_schedules, task_schedules = 
  heft.schedule_dag(dag, communication_matrix=computation_matrix, computation_matrix=computation_matrix, proc_schedules=existing_schedules, time_offset=time_offset)
```